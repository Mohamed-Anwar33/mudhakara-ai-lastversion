import type { SupabaseClient } from '@supabase/supabase-js';
import { buildFocusMap } from './focus';

/**
 * Analysis Module â€” v6 (No Hallucination)
 *
 * KEY FIX: ALWAYS sends ALL content to the AI. Never filters.
 * Focus extraction only MARKS which sections the teacher emphasized,
 * it does NOT remove the rest. This prevents hallucination.
 */

const MAX_CONTENT_CHARS = 2000000;  // 2 million chars â€” Gemini 2.5 Flash handles ~1M tokens (approx 3-4M chars)
const MAX_VALIDATION_RETRIES = 2;

// â”€â”€â”€ Types â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export interface AnalysisResult {
    summary: string;
    focusPoints: Array<{
        title: string;
        details: string;
        evidence?: { pdf_section_ids: string[]; audio_section_ids: string[] };
    }>;
    quizzes: Array<{
        question: string;
        type: string;
        options: string[];
        correctAnswer: number;
        explanation: string;
    }>;
    essayQuestions?: Array<{
        question: string;
        idealAnswer: string;
    }>;
    metadata: {
        model: string;
        contentStats: {
            pdfChars: number;
            audioChars: number;
            imageChars: number;
            method: string;
            focusMatches?: number;
        };
        generatedAt: string;
        schemaVersion: number;
    };
}

// â”€â”€â”€ Dynamic Prompt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function buildSystemPrompt(totalChars: number): string {
    const isLarge = totalChars > 15000;
    const summaryWords = isLarge ? '1500-3000' : '500-1000';
    const focusCount = isLarge ? '7-15' : '3-7';
    const focusDetailWords = isLarge ? '100-300' : '50-150';
    const quizCount = isLarge ? '10-20' : '5-10';
    const essayCount = isLarge ? '3-5' : '2-3';

    return `Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ØªØ¹Ù„ÙŠÙ…ÙŠ Ø®Ø¨ÙŠØ±. Ø³ØªØªÙ„Ù‚Ù‰ Ù…Ø­ØªÙˆÙ‰ Ø¯Ø±Ø³ ÙƒØ§Ù…Ù„ Ù…Ù† Ù…ØµØ§Ø¯Ø± Ù…ØªØ¹Ø¯Ø¯Ø© (ÙƒØªØ§Ø¨ + Ø´Ø±Ø­ ØµÙˆØªÙŠ).

âš ï¸ Ù‚Ø§Ø¹Ø¯Ø© Ø£Ø³Ø§Ø³ÙŠØ©: Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø¯Ù… Ù„Ùƒ ÙÙ‚Ø·. Ù„Ø§ ØªØ®ØªØ±Ø¹ Ø£Ùˆ ØªØ¶Ù Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø®Ø§Ø±Ø¬ Ø§Ù„Ù†Øµ. ÙƒÙ„ Ù…Ø§ ØªÙƒØªØ¨Ù‡ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹ ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø¯Ù….
${totalChars > 30000 ? '\nâš ï¸ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙƒØ¨ÙŠØ± Ø¬Ø¯Ø§Ù‹. Ø­Ù„Ù„ ÙƒÙ„ Ø¬Ø²Ø¡ Ù…Ù†Ù‡ Ø¨Ø¹Ù†Ø§ÙŠØ©.' : ''}

Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ (JSON):

1. **summary** (${summaryWords} ÙƒÙ„Ù…Ø©): Ù…Ù„Ø®Øµ Ø´Ø§Ù…Ù„ ÙˆÙ…ÙØµÙ„ Ø¬Ø¯Ø§Ù‹ ÙŠØºØ·ÙŠ:
   - ÙƒÙ„ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ ÙˆØ§Ù„Ù…ÙØ§Ù‡ÙŠÙ… ÙˆØ§Ù„ØªØ¹Ø±ÙŠÙØ§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
   - ÙƒÙ„ Ø§Ù„Ø£Ù…Ø«Ù„Ø© ÙˆØ§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª ÙˆØ§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© ÙØ¹Ù„Ø§Ù‹
   - Ø§Ø³ØªØ®Ø¯Ù… Ø¹Ù†Ø§ÙˆÙŠÙ† ÙØ±Ø¹ÙŠØ© (##) ÙˆØªÙ†Ø³ÙŠÙ‚ markdown
   - Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ù…Ù…ÙŠØ²Ø© Ø¨Ù€ â­ Ù‡ÙŠ Ù…Ø§ Ø±ÙƒØ² Ø¹Ù„ÙŠÙ‡ Ø§Ù„Ù…Ø¹Ù„Ù… â€” Ø£Ø¹Ø·Ù‡Ø§ Ø£ÙˆÙ„ÙˆÙŠØ©

2. **focusPoints** (${focusCount} Ù†Ù‚Ø·Ø©):
   - title: Ø¹Ù†ÙˆØ§Ù† ÙˆØ§Ø¶Ø­
   - details: Ø´Ø±Ø­ ØªÙØµÙŠÙ„ÙŠ (${focusDetailWords} ÙƒÙ„Ù…Ø©) Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙØ¹Ù„ÙŠ

3. **quizzes** (${quizCount} Ø³Ø¤Ø§Ù„):
   - question: Ø³Ø¤Ø§Ù„ Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙØ¹Ù„ÙŠ (Ù„ÙŠØ³ Ø¹Ø§Ù…)
   - type: "mcq" Ø£Ùˆ "tf"
   - options: 4 Ø®ÙŠØ§Ø±Ø§Øª Ø¯Ø§Ø¦Ù…Ø§Ù‹
   - correctAnswer: Ø±Ù‚Ù… (0,1,2,3)
   - explanation: Ø´Ø±Ø­

4. **essayQuestions** (${essayCount} Ø³Ø¤Ø§Ù„ Ù…Ù‚Ø§Ù„ÙŠ):
   - question: Ø³Ø¤Ø§Ù„ ÙŠØªØ·Ù„Ø¨ Ø´Ø±Ø­
   - idealAnswer: Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠØ© (100-200 ÙƒÙ„Ù…Ø©)

âš ï¸ Ù‚ÙˆØ§Ø¹Ø¯:
- correctAnswer = Ø±Ù‚Ù… ÙÙ‚Ø· (0,1,2,3)
- options = Ù…ØµÙÙˆÙØ© Ù…Ù† 4 Ø¯Ø§Ø¦Ù…Ø§Ù‹
- ÙƒÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ù…Ù„Ø®Øµ Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø¯Ù… ÙÙ‚Ø· â€” Ù„Ø§ ØªØ®ØªØ±Ø¹
- JSON Ù†Ù‚ÙŠ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø¯ÙˆÙ† \`\`\`json`;
}

// â”€â”€â”€ AI Calls â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async function callGemini(systemPrompt: string, userPrompt: string): Promise<{ parsed: any; tokensUsed: number }> {
    const apiKey = process.env.GEMINI_API_KEY;
    if (!apiKey) throw new Error('GEMINI_API_KEY not set');

    console.log(`[Analysis] Calling Gemini 2.5 Flash (${userPrompt.length} chars)...`);

    const response = await fetch(
        `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=${apiKey}`,
        {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                contents: [{ parts: [{ text: systemPrompt + '\n\n--- Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ---\n\n' + userPrompt }] }],
                generationConfig: { temperature: 0.2, maxOutputTokens: 65536, responseMimeType: 'application/json' }
            })
        }
    );

    const data = await response.json();
    if (!response.ok) throw new Error(`Gemini: ${data.error?.message || response.status}`);

    const content = data.candidates?.[0]?.content?.parts?.[0]?.text || '';
    if (!content) throw new Error('Gemini empty');

    let parsed: any;
    try { parsed = JSON.parse(content); } catch {
        const m = content.match(/```(?:json)?\s*([\s\S]*?)```/i);
        if (m) try { parsed = JSON.parse(m[1].trim()); } catch { }
    }
    if (!parsed) throw new Error(`Bad JSON from Gemini: ${content.substring(0, 300)}`);

    const tokens = data.usageMetadata?.totalTokenCount || 0;
    console.log(`[Analysis] âœ… Gemini: ${tokens} tokens, summary ${parsed.summary?.length || 0} chars`);
    return { parsed, tokensUsed: tokens };
}

async function callGPT4o(systemPrompt: string, userPrompt: string): Promise<{ parsed: any; tokensUsed: number }> {
    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) throw new Error('OPENAI_API_KEY not set');

    // GPT-4o supports 128k tokens (roughly ~400k-500k chars in Arabic). 
    // Increasing truncation limit from 60k to 300k so we don't drop the book or audio.
    const truncated = userPrompt.length > 300000 ? userPrompt.substring(0, 300000) + '\n...(Ø§Ù‚ØªØ·Ø§Ø¹)' : userPrompt;
    console.log(`[Analysis] Calling GPT-4o (${truncated.length} chars)...`);

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: { 'Authorization': `Bearer ${apiKey}`, 'Content-Type': 'application/json' },
        body: JSON.stringify({
            model: 'gpt-4o',
            messages: [{ role: 'system', content: systemPrompt }, { role: 'user', content: truncated }],
            temperature: 0.2, max_tokens: 16384, response_format: { type: 'json_object' }
        })
    });

    if (!response.ok) throw new Error(`GPT-4o error (${response.status}): ${await response.text()}`);
    const result = await response.json();
    const content = result.choices?.[0]?.message?.content;
    if (!content) throw new Error('GPT-4o empty');
    return { parsed: JSON.parse(content), tokensUsed: result.usage?.total_tokens || 0 };
}

async function callAI(systemPrompt: string, userPrompt: string): Promise<{ parsed: any; tokensUsed: number }> {
    try { return await callGemini(systemPrompt, userPrompt); }
    catch (e: any) { console.warn(`[Analysis] âš ï¸ Gemini: ${e.message}. Trying GPT-4o...`); }
    return await callGPT4o(systemPrompt, userPrompt);
}

// â”€â”€â”€ Normalize + Validate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function normalizeResponse(parsed: any): any {
    if (parsed.focus_points && !parsed.focusPoints) { parsed.focusPoints = parsed.focus_points; delete parsed.focus_points; }
    if (parsed.quiz && !parsed.quizzes) { parsed.quizzes = parsed.quiz; delete parsed.quiz; }
    if (parsed.essay_questions && !parsed.essayQuestions) { parsed.essayQuestions = parsed.essay_questions; delete parsed.essay_questions; }

    if (Array.isArray(parsed.quizzes)) {
        parsed.quizzes = parsed.quizzes.map((q: any) => {
            if (!q.options || !Array.isArray(q.options)) q.options = ['Ø£', 'Ø¨', 'Ø¬', 'Ø¯'];
            while (q.options.length < 4) q.options.push('-');
            if (typeof q.correctAnswer === 'string') {
                const idx = q.options.findIndex((o: string) => o === q.correctAnswer || o.includes(q.correctAnswer));
                q.correctAnswer = idx >= 0 ? idx : 0;
            }
            if (!q.type) q.type = 'mcq';
            if (!q.explanation) q.explanation = '';
            return q;
        });
    }
    return parsed;
}

function validateAnalysis(parsed: any): string | null {
    if (typeof parsed.summary !== 'string' || parsed.summary.length < 50) return 'summary Ù‚ØµÙŠØ±';
    if (!Array.isArray(parsed.focusPoints) || parsed.focusPoints.length === 0) return 'focusPoints ÙØ§Ø±Øº';
    if (!Array.isArray(parsed.quizzes) || parsed.quizzes.length < 3) return 'quizzes < 3';
    for (const q of parsed.quizzes) {
        if (!q.question || !q.options) return 'Ø³Ø¤Ø§Ù„ Ù†Ø§Ù‚Øµ';
        if (typeof q.correctAnswer !== 'number') return `correctAnswer not number`;
    }
    return null;
}

// â”€â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export async function generateLessonAnalysis(
    supabase: SupabaseClient<any, any, any>,
    lessonId: string
): Promise<AnalysisResult> {

    await supabase.from('lessons').update({ analysis_status: 'processing' }).eq('id', lessonId);

    try {
        // â•â•â• Step 1: ALWAYS fetch ALL content â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        console.log(`[Analysis] Fetching all content for lesson ${lessonId}`);
        const { data: allSections, error: fetchErr } = await supabase
            .from('document_sections')
            .select('id, content, chunk_index, source_type')
            .eq('lesson_id', lessonId)
            .order('source_type').order('chunk_index');

        if (fetchErr) throw new Error(`Fetch: ${fetchErr.message}`);

        const sections = {
            pdf: (allSections || []).filter((s: any) => s.source_type === 'pdf'),
            audio: (allSections || []).filter((s: any) => s.source_type === 'audio'),
            image: (allSections || []).filter((s: any) => s.source_type === 'image'),
        };

        const pdfChars = sections.pdf.reduce((s: number, r: any) => s + (r.content?.length || 0), 0);
        const audioChars = sections.audio.reduce((s: number, r: any) => s + (r.content?.length || 0), 0);
        const imageChars = sections.image.reduce((s: number, r: any) => s + (r.content?.length || 0), 0);
        const totalChars = pdfChars + audioChars + imageChars;

        console.log(`[Analysis] Content: ${pdfChars} PDF + ${audioChars} audio + ${imageChars} image = ${totalChars} chars`);
        if (totalChars < 50) throw new Error('Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø­ØªÙˆÙ‰ ÙƒØ§ÙÙ');

        // â•â•â• Step 2: Try focus extraction (markers only) â•â•â•â•â•â•â•â•
        let focusedIds = new Set<string>();
        let focusMatches = 0;

        if (audioChars > 3000) {
            try {
                console.log(`[Analysis] ğŸ” Building focus map...`);
                const focus = await buildFocusMap(supabase, lessonId);
                focusMatches = focus.stats.matchedPdfChunks;
                console.log(`[Analysis] Focus: ${focusMatches}/${focus.stats.totalPdfChunks} matched`);
                for (const sec of focus.focusPdfSections) focusedIds.add(sec.id);
            } catch (e: any) {
                console.warn(`[Analysis] âš ï¸ Focus: ${e.message}`);
            }
        } else {
            console.log(`[Analysis] âš ï¸ Audio too short (${audioChars}), skipping focus`);
        }

        // â•â•â• Step 3: Build prompt with ALL content â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        let userPrompt = '';

        if (sections.pdf.length > 0) {
            userPrompt += '=== Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙƒØªØ§Ø¨ / PDF (ÙƒØ§Ù…Ù„) ===\n\n';
            for (const sec of sections.pdf) {
                if (focusedIds.has(sec.id)) {
                    userPrompt += `â­ [Ø±ÙƒÙ‘Ø² Ø¹Ù„ÙŠÙ‡ Ø§Ù„Ù…Ø¹Ù„Ù…] ${sec.content}\n\n`;
                } else {
                    userPrompt += sec.content + '\n\n';
                }
            }
        }

        if (sections.audio.length > 0) {
            userPrompt += '=== Ø´Ø±Ø­ Ø§Ù„Ù…Ø¹Ù„Ù… (Ù†Øµ ØµÙˆØªÙŠ) ===\n\n';
            for (const sec of sections.audio) userPrompt += sec.content + '\n\n';
        }

        if (sections.image.length > 0) {
            userPrompt += '=== Ù…Ù„Ø§Ø­Ø¸Ø§Øª / ØµÙˆØ± ===\n\n';
            for (const sec of sections.image) userPrompt += sec.content + '\n\n';
        }

        if (userPrompt.length > MAX_CONTENT_CHARS) {
            userPrompt = userPrompt.substring(0, MAX_CONTENT_CHARS) + '\n...(Ø§Ù‚ØªØ·Ø§Ø¹)';
            console.warn(`[Analysis] âš ï¸ Content truncated from ${totalChars} to ${MAX_CONTENT_CHARS} chars`);
        }

        const method = focusedIds.size > 0 ? 'all-content+focus' : 'all-content';
        console.log(`[Analysis] Prompt: ${userPrompt.length} chars, method: ${method}`);

        // â•â•â• Step 4: Call AI â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        const systemPrompt = buildSystemPrompt(totalChars);
        let parsed: any = null;
        let totalTokens = 0;
        let lastErr: string | null = null;

        for (let attempt = 0; attempt <= MAX_VALIDATION_RETRIES; attempt++) {
            const prompt = attempt === 0 ? userPrompt : `Ø±ÙÙØ¶: "${lastErr}". Ø£Ø¹Ø¯.\n\n${userPrompt}`;
            const result = await callAI(systemPrompt, prompt);
            totalTokens += result.tokensUsed;
            result.parsed = normalizeResponse(result.parsed);
            lastErr = validateAnalysis(result.parsed);
            if (!lastErr) { parsed = result.parsed; break; }
            console.warn(`[Analysis] Validation #${attempt + 1}: ${lastErr}`);
        }

        if (!parsed) throw new Error(`Validation: ${lastErr}`);

        // â•â•â• Step 5: Save â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        const analysisResult: AnalysisResult = {
            summary: parsed.summary,
            focusPoints: parsed.focusPoints,
            quizzes: parsed.quizzes,
            essayQuestions: parsed.essayQuestions || [],
            metadata: {
                model: 'gemini-2.5-flash',
                contentStats: { pdfChars, audioChars, imageChars, method, focusMatches },
                generatedAt: new Date().toISOString(),
                schemaVersion: 6
            }
        };

        await supabase.from('lessons')
            .update({ analysis_result: analysisResult, analysis_status: 'completed' })
            .eq('id', lessonId);

        console.log(`[Analysis] âœ… Done: ${totalTokens} tokens, summary=${parsed.summary.length} chars, ${parsed.focusPoints.length} focus, ${parsed.quizzes.length} quiz, ${parsed.essayQuestions?.length || 0} essay`);
        return analysisResult;

    } catch (err: any) {
        console.error(`[Analysis] âŒ ${lessonId}: ${err.message}`);
        await supabase.from('lessons')
            .update({ analysis_status: 'failed', analysis_result: { error: err.message } })
            .eq('id', lessonId);
        throw err;
    }
}

export async function rerunLessonAnalysis(
    supabase: SupabaseClient<any, any, any>,
    lessonId: string
): Promise<AnalysisResult> {
    return generateLessonAnalysis(supabase, lessonId);
}
