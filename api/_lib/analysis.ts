import type { SupabaseClient } from '@supabase/supabase-js';
import { buildFocusMap } from './focus';

/**
 * Analysis Module â€” v6 (No Hallucination)
 *
 * KEY FIX: ALWAYS sends ALL content to the AI. Never filters.
 * Focus extraction only MARKS which sections the teacher emphasized,
 * it does NOT remove the rest. This prevents hallucination.
 */

const MAX_CONTENT_CHARS = 2000000;  // 2 million chars â€” Gemini 2.5 Flash handles ~1M tokens (approx 3-4M chars)
const MAX_VALIDATION_RETRIES = 2;

// â”€â”€â”€ Types â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export interface AnalysisResult {
    summary: string;
    focusPoints: Array<{
        title: string;
        details: string;
        evidence?: { pdf_section_ids: string[]; audio_section_ids: string[] };
    }>;
    quizzes: Array<{
        question: string;
        type: string;
        options: string[];
        correctAnswer: number;
        explanation: string;
    }>;
    essayQuestions?: Array<{
        question: string;
        idealAnswer: string;
    }>;
    metadata: {
        model: string;
        contentStats: {
            pdfChars: number;
            audioChars: number;
            imageChars: number;
            method: string;
            focusMatches?: number;
        };
        generatedAt: string;
        schemaVersion: number;
    };
}

// â”€â”€â”€ Dynamic Prompt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function buildSystemPrompt(totalChars: number): string {
    const isLarge = totalChars > 50000;
    const summaryWords = isLarge ? '2000-4000' : '800-1500';
    const focusCount = isLarge ? '8-15' : '5-8';
    const focusDetailWords = isLarge ? '150-300' : '80-150';
    const quizCount = isLarge ? '15-25' : '8-15';
    const essayCount = isLarge ? '4-6' : '3-4';

    return `Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ØªØ¹Ù„ÙŠÙ…ÙŠ Ø®Ø¨ÙŠØ± ÙˆØ¹Ø¨Ù‚Ø±ÙŠ. Ø³ØªØªÙ„Ù‚Ù‰ Ù…Ø­ØªÙˆÙ‰ ÙƒØªØ§Ø¨/Ù…Ù„Ø²Ù…Ø© ÙƒØ§Ù…Ù„Ø© + Ø´Ø±Ø­ ØµÙˆØªÙŠ Ù„Ù„Ù…Ø¹Ù„Ù… (Ø¥Ù† ÙˆÙØ¬Ø¯) + ØµÙˆØ±.

âš ï¸ Ù‚Ø§Ø¹Ø¯Ø© Ø£Ø³Ø§Ø³ÙŠØ©: Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø¯Ù… Ù„Ùƒ ÙÙ‚Ø·. Ù„Ø§ ØªØ®ØªØ±Ø¹ Ø£Ùˆ ØªØ¶Ù Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø®Ø§Ø±Ø¬ Ø§Ù„Ù†Øµ.

Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø¥Ø®Ø±Ø§Ø¬Ù‡ Ø¨ØµÙŠØºØ© (JSON) Ø­ØµØ±Ø§Ù‹:

1. **summary** (${summaryWords} ÙƒÙ„Ù…Ø©): Ù…Ù„Ø®Øµ Ø´Ø§Ù…Ù„ ÙŠØºØ·ÙŠ Ø§Ù„ÙƒØªØ§Ø¨ ÙƒØ§Ù…Ù„Ø§Ù‹ Ù…Ù† Ø£ÙˆÙ„ ØµÙØ­Ø© Ù„Ø¢Ø®Ø± ØµÙØ­Ø©:
   - **Ù‚Ø§Ø¹Ø¯Ø© Ø­Ø§Ø³Ù…Ø©**: Ù‚Ø³Ù‘Ù… Ø§Ù„Ù…Ù„Ø®Øµ Ø¥Ù„Ù‰ Ø£Ù‚Ø³Ø§Ù… Ø¨Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø¯Ø±ÙˆØ³/Ø§Ù„ÙØµÙˆÙ„ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„ÙƒØªØ§Ø¨.
   - ÙƒÙ„ Ù‚Ø³Ù… ÙŠØ¨Ø¯Ø£ Ø¨Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø¯Ø±Ø³ ÙƒÙ€ ## (Ù…Ø«Ù„Ø§Ù‹: ## Ø§Ù„Ø¯Ø±Ø³ Ø§Ù„Ø£ÙˆÙ„: Ø§Ù„Ù‡Ù…Ø²Ø©)
   - Ù„Ø®Ù‘Øµ Ù…Ø­ØªÙˆÙ‰ ÙƒÙ„ Ø¯Ø±Ø³ Ø¨Ø§Ù„ØªÙØµÙŠÙ„: Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ…ØŒ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ØŒ Ø§Ù„Ø£Ù…Ø«Ù„Ø©ØŒ Ø§Ù„ØªØ¹Ø±ÙŠÙØ§Øª.
   - Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ÙƒØªØ§Ø¨ ÙƒØªØ§Ø¨ Ø­Ù„ÙˆÙ„ØŒ Ø§Ø³ØªØ®Ù„Øµ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ ÙˆØ§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ù…Ù† Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª.
   - Ø§Ø¯Ù…Ø¬ Ø´Ø±Ø­ Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„ØµÙˆØªÙŠ ÙÙŠ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©.
   - Ø§Ø³ØªØ®Ø¯Ù… ØªÙ†Ø³ÙŠÙ‚ Markdown Ø¨Ø¹Ù†Ø§ÙˆÙŠÙ† ÙˆÙ‚ÙˆØ§Ø¦Ù… ÙˆÙ†Ù‚Ø§Ø·.

2. **focusPoints** (${focusCount} Ù†Ù‚Ø·Ø©) â€” **Ù‡Ø°Ù‡ Ø§Ù„Ù†Ù‚Ø§Ø· ØªÙ…Ø«Ù„ Ù…Ø§ Ø±ÙƒÙ‘Ø² Ø¹Ù„ÙŠÙ‡ Ø§Ù„Ù…Ø¹Ù„Ù… ÙÙŠ Ø´Ø±Ø­Ù‡ Ø§Ù„ØµÙˆØªÙŠ**:
   - title: Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„ØªÙŠ Ø±ÙƒÙ‘Ø² Ø¹Ù„ÙŠÙ‡Ø§ Ø§Ù„Ù…Ø¹Ù„Ù….
   - details: Ø´Ø±Ø­ ØªÙØµÙŠÙ„ÙŠ (${focusDetailWords} ÙƒÙ„Ù…Ø©) ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ù…Ø§ Ù‚Ø§Ù„Ù‡ Ø§Ù„Ù…Ø¹Ù„Ù… ÙÙŠ Ø§Ù„ØµÙˆØª ÙˆÙ…Ø§ Ù‡Ùˆ Ù…ÙƒØªÙˆØ¨ ÙÙŠ Ø§Ù„ÙƒØªØ§Ø¨.
   - **Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ù…Ù…ÙŠØ²Ø© Ø¨Ù€ â­ Ù‡ÙŠ Ø§Ù„ØªÙŠ Ø·Ø§Ø¨Ù‚Øª Ø´Ø±Ø­ Ø§Ù„Ù…Ø¹Ù„Ù… â€” Ø±ÙƒÙ‘Ø² Ø¹Ù„ÙŠÙ‡Ø§ ÙÙŠ focus.**
   - Ø¥Ø°Ø§ Ù„Ù… ÙŠÙˆØ¬Ø¯ Ø´Ø±Ø­ ØµÙˆØªÙŠØŒ Ø§Ø¬Ø¹Ù„ focusPoints = Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø£Ù‡Ù… ÙÙŠ Ø§Ù„ÙƒØªØ§Ø¨.

3. **quizzes** (${quizCount} Ø³Ø¤Ø§Ù„):
   - question: Ø³Ø¤Ø§Ù„ Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙØ¹Ù„ÙŠ (Ù„ÙŠØ³ Ø¹Ø§Ù…)
   - type: "mcq" Ø£Ùˆ "tf"
   - options: 4 Ø®ÙŠØ§Ø±Ø§Øª Ø¯Ø§Ø¦Ù…Ø§Ù‹ (Ø­ØªÙ‰ ØµØ­/Ø®Ø·Ø£: ["ØµØ­", "Ø®Ø·Ø£", "-", "-"])
   - correctAnswer: Ø±Ù‚Ù… (0,1,2,3)
   - explanation: Ø´Ø±Ø­ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
   - **Ø£Ø¹Ø·Ù Ø£ÙˆÙ„ÙˆÙŠØ© Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø°ÙŠ Ø±ÙƒÙ‘Ø² Ø¹Ù„ÙŠÙ‡ Ø§Ù„Ù…Ø¹Ù„Ù… (â­)**

4. **essayQuestions** (${essayCount} Ø³Ø¤Ø§Ù„ Ù…Ù‚Ø§Ù„ÙŠ):
   - question: Ø³Ø¤Ø§Ù„ ÙŠØªØ·Ù„Ø¨ Ø´Ø±Ø­
   - idealAnswer: Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠØ© (150-300 ÙƒÙ„Ù…Ø©)

âš ï¸ Ù‚ÙˆØ§Ø¹Ø¯ ØµØ§Ø±Ù…Ø©:
- correctAnswer = Ø±Ù‚Ù… ÙÙ‚Ø· (0,1,2,3)
- options = Ù…ØµÙÙˆÙØ© Ù…Ù† 4 Ø¯Ø§Ø¦Ù…Ø§Ù‹
- ÙƒÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ù…Ù„Ø®Øµ Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø¯Ù… ÙÙ‚Ø·
- Ø§Ù„Ù…Ù„Ø®Øµ ÙŠØºØ·ÙŠ Ø§Ù„ÙƒØªØ§Ø¨ **ÙƒØ§Ù…Ù„Ø§Ù‹** Ù…Ù‚Ø³Ù… Ø¨Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø¯Ø±ÙˆØ³
- JSON Ù†Ù‚ÙŠ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø¯ÙˆÙ† \`\`\`json`;
}

// â”€â”€â”€ AI Calls â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

/** Try to repair truncated JSON (common with large outputs) */
function repairTruncatedJSON(raw: string): any | null {
    try { return JSON.parse(raw); } catch { }

    const m = raw.match(/```(?:json)?\s*([\s\S]*?)```/i);
    if (m) try { return JSON.parse(m[1].trim()); } catch { }

    let fixed = raw.trim();
    fixed = fixed.replace(/,?\s*"[^"]*$/, '');
    // Remove unterminated string values at the end (even if they contain quotes)
    fixed = fixed.replace(/,?\s*"[^"]+"\s*:\s*"[^]*$/, '');
    fixed = fixed.replace(/,?\s*"[^"]*":\s*$/, '');
    fixed = fixed.replace(/,\s*$/, '');

    let openBraces = 0, openBrackets = 0, inString = false, escape = false;
    for (const ch of fixed) {
        if (escape) { escape = false; continue; }
        if (ch === '\\') { escape = true; continue; }
        if (ch === '"') { inString = !inString; continue; }
        if (inString) continue;
        if (ch === '{') openBraces++;
        if (ch === '}') openBraces--;
        if (ch === '[') openBrackets++;
        if (ch === ']') openBrackets--;
    }
    if (inString) fixed += '"';
    for (let i = 0; i < openBrackets; i++) fixed += ']';
    for (let i = 0; i < openBraces; i++) fixed += '}';

    try {
        const parsed = JSON.parse(fixed);
        console.log(`[Analysis] ğŸ”§ Repaired truncated JSON`);
        return parsed;
    } catch { return null; }
}

/** Call Gemini for TEXT output (no JSON constraint â€” for summaries) */
async function callGeminiText(prompt: string): Promise<{ text: string; tokensUsed: number }> {
    const apiKey = process.env.GEMINI_API_KEY;
    if (!apiKey) throw new Error('GEMINI_API_KEY not set');
    console.log(`[Analysis] Calling Gemini TEXT (${prompt.length} chars)...`);

    const response = await fetch(
        `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=${apiKey}`,
        {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                contents: [{ parts: [{ text: prompt }] }],
                generationConfig: { temperature: 0.2, maxOutputTokens: 65536 }
            })
        }
    );

    const data = await response.json();
    if (!response.ok) throw new Error(`Gemini: ${data.error?.message || response.status}`);

    const parts = data.candidates?.[0]?.content?.parts || [];
    const text = parts.filter((p: any) => p.text).map((p: any) => p.text).join('').trim();
    const tokens = data.usageMetadata?.totalTokenCount || 0;
    console.log(`[Analysis] âœ… Gemini TEXT: ${text.length} chars, ${tokens} tokens`);
    return { text, tokensUsed: tokens };
}

/** Call Gemini for JSON output (for quizzes/focus points) */
async function callGeminiJSON(prompt: string): Promise<{ parsed: any; tokensUsed: number }> {
    const apiKey = process.env.GEMINI_API_KEY;
    if (!apiKey) throw new Error('GEMINI_API_KEY not set');
    console.log(`[Analysis] Calling Gemini JSON (${prompt.length} chars)...`);

    const response = await fetch(
        `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=${apiKey}`,
        {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                contents: [{ parts: [{ text: prompt }] }],
                generationConfig: { temperature: 0.2, maxOutputTokens: 16384, responseMimeType: 'application/json' }
            })
        }
    );

    const data = await response.json();
    if (!response.ok) throw new Error(`Gemini: ${data.error?.message || response.status}`);

    const parts = data.candidates?.[0]?.content?.parts || [];
    const content = parts.filter((p: any) => p.text).map((p: any) => p.text).join('').trim();
    if (!content) throw new Error('Gemini JSON empty');

    const parsed = repairTruncatedJSON(content);
    if (!parsed) throw new Error(`Bad JSON from Gemini: ${content.substring(0, 200)}`);

    const tokens = data.usageMetadata?.totalTokenCount || 0;
    console.log(`[Analysis] âœ… Gemini JSON: ${tokens} tokens`);
    return { parsed, tokensUsed: tokens };
}

/** GPT-4o fallback for JSON */
async function callGPT4oJSON(prompt: string): Promise<{ parsed: any; tokensUsed: number }> {
    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) throw new Error('OPENAI_API_KEY not set');

    const MAX_CHARS = 100000;
    const truncated = prompt.length > MAX_CHARS ? prompt.substring(0, MAX_CHARS) + '\n...(Ø§Ù‚ØªØ·Ø§Ø¹)' : prompt;
    console.log(`[Analysis] Calling GPT-4o JSON (${truncated.length} chars)...`);

    let response;
    for (let attempt = 1; attempt <= 3; attempt++) {
        response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: { 'Authorization': `Bearer ${apiKey}`, 'Content-Type': 'application/json' },
            body: JSON.stringify({
                model: 'gpt-4o',
                messages: [{ role: 'user', content: truncated }],
                temperature: 0.2, max_tokens: 16384, response_format: { type: 'json_object' }
            })
        });

        if (response.status === 429 && attempt < 3) {
            console.log(`[Analysis] âš ï¸ GPT-4o 429 (Too Many Requests), retrying in ${attempt * 3}s...`);
            await new Promise(r => setTimeout(r, attempt * 3000));
            continue;
        }
        break;
    }

    if (!response || !response.ok) throw new Error(`GPT-4o error (${response?.status})`);
    const result = await response.json();
    const content = result.choices?.[0]?.message?.content;
    if (!content) throw new Error('GPT-4o empty');
    return { parsed: JSON.parse(content), tokensUsed: result.usage?.total_tokens || 0 };
}

// â”€â”€â”€ Normalize + Validate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function normalizeResponse(parsed: any): any {
    if (parsed.focus_points && !parsed.focusPoints) { parsed.focusPoints = parsed.focus_points; delete parsed.focus_points; }
    if (parsed.quiz && !parsed.quizzes) { parsed.quizzes = parsed.quiz; delete parsed.quiz; }
    if (parsed.essay_questions && !parsed.essayQuestions) { parsed.essayQuestions = parsed.essay_questions; delete parsed.essay_questions; }

    if (Array.isArray(parsed.quizzes)) {
        parsed.quizzes = parsed.quizzes.map((q: any) => {
            if (!q.options || !Array.isArray(q.options)) q.options = ['Ø£', 'Ø¨', 'Ø¬', 'Ø¯'];
            while (q.options.length < 4) q.options.push('-');
            if (typeof q.correctAnswer === 'string') {
                const idx = q.options.findIndex((o: string) => o === q.correctAnswer || o.includes(q.correctAnswer));
                q.correctAnswer = idx >= 0 ? idx : 0;
            }
            if (!q.type) q.type = 'mcq';
            if (!q.explanation) q.explanation = '';
            return q;
        });
    }
    return parsed;
}

function validateAnalysis(parsed: any): string | null {
    if (typeof parsed.summary !== 'string' || parsed.summary.length < 50) return 'summary Ù‚ØµÙŠØ±';
    if (!Array.isArray(parsed.focusPoints) || parsed.focusPoints.length === 0) return 'focusPoints ÙØ§Ø±Øº';
    if (!Array.isArray(parsed.quizzes) || parsed.quizzes.length < 3) return 'quizzes < 3';
    for (const q of parsed.quizzes) {
        if (!q.question || !q.options) return 'Ø³Ø¤Ø§Ù„ Ù†Ø§Ù‚Øµ';
        if (typeof q.correctAnswer !== 'number') return `correctAnswer not number`;
    }
    return null;
}

// â”€â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export async function generateLessonAnalysis(
    supabase: SupabaseClient<any, any, any>,
    lessonId: string,
    onProgress?: (step: string, message: string, percent: number) => void
): Promise<AnalysisResult> {

    const progress = onProgress || (() => { });
    progress('starting', 'Ø¬Ø§Ø±ÙŠ ØªØ¬Ù‡ÙŠØ² Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ­Ù„ÙŠÙ„...', 5);
    await supabase.from('lessons').update({ analysis_status: 'processing' }).eq('id', lessonId);

    try {
        // â•â•â• Step 1: ALWAYS fetch ALL content â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        progress('fetching', 'Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ ÙƒÙ„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¯Ø±Ø³ (PDF + ØµÙˆØª + ØµÙˆØ±)...', 10);
        console.log(`[Analysis] Fetching all content for lesson ${lessonId}`);
        const { data: allSections, error: fetchErr } = await supabase
            .from('document_sections')
            .select('id, content, chunk_index, source_type, source_file_id')
            .eq('lesson_id', lessonId)
            .order('source_type')
            .order('source_file_id')
            .order('chunk_index');

        if (fetchErr) throw new Error(`Fetch: ${fetchErr.message}`);

        const sections = {
            pdf: (allSections || []).filter((s: any) => s.source_type === 'pdf'),
            audio: (allSections || []).filter((s: any) => s.source_type === 'audio'),
            image: (allSections || []).filter((s: any) => s.source_type === 'image'),
        };

        const pdfChars = sections.pdf.reduce((s: number, r: any) => s + (r.content?.length || 0), 0);
        const audioChars = sections.audio.reduce((s: number, r: any) => s + (r.content?.length || 0), 0);
        const imageChars = sections.image.reduce((s: number, r: any) => s + (r.content?.length || 0), 0);
        const totalChars = pdfChars + audioChars + imageChars;

        console.log(`[Analysis] Content: ${pdfChars} PDF + ${audioChars} audio + ${imageChars} image = ${totalChars} chars`);
        if (totalChars < 50) throw new Error('Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø­ØªÙˆÙ‰ ÙƒØ§ÙÙ');

        // â•â•â• Step 2: Try focus extraction (markers only) â•â•â•â•â•â•â•â•
        let focusedIds = new Set<string>();
        let focusMatches = 0;

        if (audioChars > 3000) {
            try {
                progress('focus', 'Ø¬Ø§Ø±ÙŠ Ù…Ø·Ø§Ø¨Ù‚Ø© Ø´Ø±Ø­ Ø§Ù„Ù…Ø¹Ù„Ù… Ù…Ø¹ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙƒØªØ§Ø¨...', 25);
                console.log(`[Analysis] ğŸ” Building focus map...`);
                const focus = await buildFocusMap(supabase, lessonId);
                focusMatches = focus.stats.matchedPdfChunks;
                console.log(`[Analysis] Focus: ${focusMatches}/${focus.stats.totalPdfChunks} matched`);
                for (const sec of focus.focusPdfSections) focusedIds.add(sec.id);
            } catch (e: any) {
                console.warn(`[Analysis] âš ï¸ Focus: ${e.message}`);
            }
        } else {
            console.log(`[Analysis] âš ï¸ Audio too short (${audioChars}), skipping focus`);
        }

        // â•â•â• Step 3: Build prompts â€” full lesson coverage (PDF + images + audio) â•â•â•
        let method = 'all-content';

        // Build summary source content from all lesson sources.
        let summarySourceContent = '';
        if (sections.pdf.length > 0) {
            for (const sec of sections.pdf) {
                if (focusedIds.has(sec.id)) {
                    summarySourceContent += `â­ [Ø±ÙƒÙ‘Ø² Ø¹Ù„ÙŠÙ‡ Ø§Ù„Ù…Ø¹Ù„Ù… ÙÙŠ Ø´Ø±Ø­Ù‡] ${sec.content}\n\n`;
                    method = 'all-content+focus';
                } else {
                    summarySourceContent += sec.content + '\n\n';
                }
            }
        }

        // Add image OCR text.
        if (sections.image.length > 0) {
            summarySourceContent += '\n=== Ù…Ù„Ø§Ø­Ø¸Ø§Øª / ØµÙˆØ± ===\n\n';
            for (const sec of sections.image) summarySourceContent += sec.content + '\n\n';
        }

        // Add audio transcription to guarantee lecture coverage in summary.
        if (sections.audio.length > 0) {
            summarySourceContent += '\n=== Ø´Ø±Ø­ Ø§Ù„Ù…Ø¹Ù„Ù… (ØªÙØ±ÙŠØº ØµÙˆØªÙŠ) ===\n\n';
            for (const sec of sections.audio) summarySourceContent += sec.content + '\n\n';
        }

        const finalMethod = focusMatches > 0 ? method + '+focus' : method;
        console.log(`[Analysis] Summary source content: ${summarySourceContent.length} chars, method: ${finalMethod}`);

        // â•â•â• Step 4A: Generate SUMMARY in BATCHES (book + images + lectures) â•â•â•â•
        progress('analyzing', 'Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙŠÙˆÙ„Ù‘Ø¯ Ù…Ù„Ø®ØµØ§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹ Ù„Ù„ÙƒØªØ§Ø¨ ÙˆØ§Ù„Ù…Ø­Ø§Ø¶Ø±Ø§Øª...', 30);

        let summary = '';
        let totalTokens = 0;

        // â”€â”€â”€ Noise filter: remove repetitive/boilerplate paragraphs â”€â”€â”€
        const paragraphs = summarySourceContent.split('\n\n').filter((p: string) => p.trim().length > 30);
        const seen = new Map<string, number>();
        const cleanParagraphs: string[] = [];

        for (const p of paragraphs) {
            // Create a fingerprint: first 80 chars normalized
            const fingerprint = p.trim().substring(0, 80).replace(/\s+/g, ' ');
            const count = (seen.get(fingerprint) || 0) + 1;
            seen.set(fingerprint, count);

            // Skip if this fingerprint appeared more than twice
            if (count > 2) continue;

            // Skip common boilerplate patterns
            if (p.includes('Ø­ÙÙ„ÙÙ‘ Ù‡Ø°Ø§ Ø§Ù„ÙƒØªØ§Ø¨ ÙˆØ±ÙØªÙÙ‘Ø¨') ||
                p.includes('Ø§Ù„Ù…Ù„Ù Ù…Ø¯Ø¹ÙˆÙ…') ||
                (p.includes('ØªØ³Ù‡ÙŠÙ„Ø§Ù‹ ÙˆØªÙŠØ³ÙŠØ±Ù‹Ø§') && p.length < 200)) continue;

            cleanParagraphs.push(p);
        }

        const cleanContent = cleanParagraphs.join('\n\n');
        const noiseRemoved = summarySourceContent.length - cleanContent.length;
        if (noiseRemoved > 1000) {
            console.log(`[Analysis] ğŸ§¹ Noise filter: removed ${noiseRemoved} chars of repetitive content`);
        }

        // â”€â”€â”€ Split clean full content into batches with OVERLAP â”€â”€â”€
        const BATCH_SIZE = 40000;
        const OVERLAP_PARAGRAPHS = 3; // Keep last 3 paragraphs in next chunk to prevent cutting rules
        const batches: string[] = [];
        let currentBatch: string[] = [];
        let currentLen = 0;

        for (let i = 0; i < cleanParagraphs.length; i++) {
            const part = cleanParagraphs[i];
            if (currentLen + part.length > BATCH_SIZE && currentLen > 5000) {
                batches.push(currentBatch.join('\n\n'));
                // Start new batch with overlap from previous
                const startIndex = Math.max(0, i - OVERLAP_PARAGRAPHS);
                currentBatch = cleanParagraphs.slice(startIndex, i + 1);
                currentLen = currentBatch.reduce((sum, p) => sum + p.length + 2, 0); // +2 for '\n\n'
            } else {
                currentBatch.push(part);
                currentLen += part.length + 2;
            }
        }
        // Don't push the last batch if it's completely redundant (just the overlap)
        if (currentBatch.length > Math.min(OVERLAP_PARAGRAPHS + 1, cleanParagraphs.length)) {
            batches.push(currentBatch.join('\n\n'));
        }

        console.log(`[Analysis] Splitting into ${batches.length} summary batches (${batches.map(b => b.length).join(', ')} chars)`);

        const summaryParts: string[] = [];
        for (let i = 0; i < batches.length; i++) {
            const batchNum = i + 1;
            const totalBatches = batches.length;
            progress('analyzing', `ÙŠÙ„Ø®Ù‘Øµ Ø§Ù„Ø¬Ø²Ø¡ ${batchNum} Ù…Ù† ${totalBatches}...`, 30 + Math.round((i / totalBatches) * 30));

            const batchPrompt = `Ø£Ù†Øª Ø§Ù„Ø®Ø¨ÙŠØ± Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ Ø¹Ù† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ù…Ù† Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø²Ø¡ (Ø§Ù„Ø¬Ø²Ø¡ ${batchNum} Ù…Ù† ${totalBatches}).
Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø¯Ø±ÙˆØ³ ÙˆØ§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© *ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ ÙÙ‚Ø·*.

âš ï¸âš ï¸âš ï¸ Ù‚ÙˆØ§Ø¹Ø¯ Ø­Ø§Ø³Ù…Ø©:
1. **Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¹Ù„Ù…ÙŠØ© ÙˆØ§Ù„Ù†Ø­ÙˆÙŠØ© ÙˆØ§Ù„Ø¥Ù…Ù„Ø§Ø¦ÙŠØ©.**
2. **ØªØ¬Ø§Ù‡Ù„ ØªÙ…Ø§Ù…Ø§Ù‹ Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø­Ø±Ø©ØŒ Ø§Ù„Ù‚ØµØµ (Ù…Ø«Ù„ Ù‚ØµØ© Ø§Ù„Ù†Ø§Ø³Ùƒ ÙˆØ§Ø¨Ù† Ø¹Ø±Ø³)ØŒ ÙˆØªØ¯Ø±ÙŠØ¨Ø§Øª Ø§Ù„Ø§Ø³ØªÙŠØ¹Ø§Ø¨ Ø§Ù„Ù‚Ø±Ø§Ø¦ÙŠ.**
3. **Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹:** Ø¥Ø°Ø§ Ø§Ù†Ù‚Ø·Ø¹Øª Ù‚Ø§Ø¹Ø¯Ø© ÙÙŠ Ø¢Ø®Ø± Ø§Ù„Ù†ØµØŒ Ù„Ø®Ù‘Øµ Ù…Ø§ Ù‡Ùˆ Ù…ÙˆØ¬ÙˆØ¯ Ø£Ù…Ø§Ù…Ùƒ ÙÙ‚Ø· ÙˆØ§Ø¬Ø¹Ù„ partial=trueØŒ ÙˆÙ„Ø§ ØªØ¤Ù„Ù Ø§Ù„Ø¨Ø§Ù‚ÙŠ Ù…Ù† Ø¹Ù†Ø¯Ùƒ!
4. **Ù„Ø§ ØªØ´ØªÙƒÙŠ Ù…Ù† Ù†Ù‚Øµ Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„ÙÙ‡Ø±Ø³.** Ù‡Ø°Ø§ Ù…Ø¬Ø±Ø¯ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„ÙƒØªØ§Ø¨.
5. **Ø§Ø­Ø°Ø± Ù…Ù† Ø¯Ù…Ø¬ Ø§Ù„Ø¯Ø±ÙˆØ³:** Ø§ÙØµÙ„ ØªÙ…Ø§Ù…Ø§Ù‹ Ø¨ÙŠÙ† Ø§Ù„Ø¯Ø±ÙˆØ³ Ø§Ù„Ù…Ø³ØªÙ‚Ù„Ø© (Ù…Ø«Ù„ ÙØµÙ„ "Ø§Ù„Ù…Ù‚Ø§Ù„" Ø¹Ù† "Ø§Ù„ØªÙ‚Ø±ÙŠØ±").
6. **Ù„Ø§ ØªØªÙˆÙ‚Ù Ù‚Ø¨Ù„ Ø§Ù„Ù†Ù‡Ø§ÙŠØ©:** ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØªÙ„Ø®ÙŠØµ Ø§Ù„Ø¯Ø±ÙˆØ³ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø¢Ø®Ø± Ø³Ø·Ø± Ù…Ù† Ù‡Ø°Ø§ Ø§Ù„Ø¬Ø²Ø¡.
7. **Ø§Ù„Ø¹Ù…Ù‚ ÙˆØ§Ù„ØªÙØµÙŠÙ„ Ø§Ù„Ø´Ø¯ÙŠØ¯ (Ø£Ù‡Ù… Ù‚Ø§Ø¹Ø¯Ø©):** Ø¥ÙŠØ§Ùƒ Ø£Ù† ØªØ®ØªØµØ± Ø´Ø±Ø­ Ø£ÙŠ Ù…Ø­Ø§Ø¶Ø±Ø©! Ø§ÙƒØªØ¨ ÙƒÙ„ Ù†Ù‚Ø·Ø©ØŒ ÙƒÙ„ ØªØ¹Ø±ÙŠÙØŒ ÙƒÙ„ Ø´Ø±Ø·ØŒ ÙˆÙƒÙ„ Ù…Ø«Ø§Ù„. Ø§Ù„Ø´Ø±Ø­ Ø§Ù„Ø³Ø·Ø­ÙŠ Ù…Ù…Ù†ÙˆØ¹ Ù‚Ø·Ø¹Ø§Ù‹.

Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© (Ù†Øµ Markdown Ù…Ù†Ø³Ù‚ Ø¨Ø¯Ù‚Ø© ÙˆØ¨Ø£Ù‚ØµÙ‰ ØªÙØµÙŠÙ„):
- Ø§Ø³ØªØ®Ø¯Ù… Ø¹Ù†ÙˆØ§Ù† Ù…Ù† Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ø§Ù†ÙŠ (\`##\`) Ù„ÙƒÙ„ Ø¯Ø±Ø³ Ø¬Ø¯ÙŠØ¯ (Ù…Ø«Ù„: \`## Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„ÙØ¹Ù„ÙŠØ©\` Ø£Ùˆ \`## ÙƒØªØ§Ø¨Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ±\`).
- ØªØ­Øª ÙƒÙ„ Ø¹Ù†ÙˆØ§Ù† Ø¯Ø±Ø³ØŒ Ø§ÙƒØªØ¨ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ ÙˆØ§Ù„Ù…ÙØ§Ù‡ÙŠÙ… ÙˆØ§Ù„Ø´Ø±Ø­ Ø¨Ø§Ù„ØªÙØµÙŠÙ„ Ø§Ù„Ù…Ù…Ù„ ÙÙŠ Ø´ÙƒÙ„ Ù†Ù‚Ø§Ø· (Ø¹Ù„Ø§Ù…Ø© \`-\` ÙÙŠ Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø³Ø·Ø±).
- Ù„Ø§ ØªØªØ±Ùƒ Ø£ÙŠ ØªÙØµÙŠÙ„Ø© Ø¹Ù„Ù…ÙŠØ© Ø£Ùˆ Ù„ØºÙˆÙŠØ© Ø£Ùˆ Ø¥Ù…Ù„Ø§Ø¦ÙŠØ© Ø¥Ù„Ø§ ÙˆØ°ÙƒØ±ØªÙ‡Ø§.
- Ù„Ø§ ØªÙƒØªØ¨ Ù…Ù‚Ø¯Ù…Ø§Øª Ø£Ùˆ Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§ØªØŒ Ø§Ø¯Ø®Ù„ ÙÙŠ Ø³Ø±Ø¯ Ø§Ù„Ø¯Ø±ÙˆØ³ ÙˆÙ‚ÙˆØ§Ø¹Ø¯Ù‡Ø§ Ù…Ø¨Ø§Ø´Ø±Ø©.

--- Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¬Ø²Ø¡ ${batchNum}/${totalBatches} ---

${batches[i]}`;

            let batchResult = '';
            for (let attempt = 1; attempt <= 3; attempt++) {
                try {
                    const result = await callGeminiText(batchPrompt);
                    batchResult = result.text;
                    totalTokens += result.tokensUsed;
                    console.log(`[Analysis] Batch ${batchNum}/${totalBatches}: ${batchResult.length} chars (attempt ${attempt})`);
                    break;
                } catch (e: any) {
                    console.warn(`[Analysis] âš ï¸ Batch ${batchNum} attempt ${attempt} failed: ${e.message}`);
                    if (attempt === 3) batchResult = `[ÙØ´Ù„ ØªÙ„Ø®ÙŠØµ Ø§Ù„Ø¬Ø²Ø¡ ${batchNum}]`;
                    else await new Promise(r => setTimeout(r, 2000));
                }
            }
            if (batchResult && batchResult.length > 50) {
                summaryParts.push(batchResult);
            }
        }

        // â”€â”€â”€ Phase 4: Merge and Deduplicate Chunks via Markdown Parsing â”€â”€â”€
        console.log(`[Analysis] ğŸ”„ Merging and deduplicating ${summaryParts.length} Text chunks...`);
        const mergedLectures = new Map<string, { title: string; content: string[] }>();

        for (const chunkText of summaryParts) {
            if (typeof chunkText !== 'string') continue;

            const lines = chunkText.split('\n');
            let currentTitle = '';

            for (let line of lines) {
                line = line.trimEnd();
                if (!line.trim()) continue;

                if (line.trim().startsWith('## ')) {
                    const rawTitle = line.trim().substring(3).trim();
                    if (rawTitle.length < 2) continue;

                    // Normalize title
                    currentTitle = rawTitle.replace(/^[\d\.\-\s]+/, '').trim();

                    if (!mergedLectures.has(currentTitle)) {
                        mergedLectures.set(currentTitle, { title: currentTitle, content: [] });
                    }
                } else if (currentTitle && line.trim().length > 5) {
                    // Keep ALL content lines: bullets, paragraphs, sub-headers, etc.
                    const contentArr = mergedLectures.get(currentTitle)!.content;
                    const trimmed = line.trim();
                    // Dedup: skip exact duplicates
                    if (!contentArr.some(existing => existing.trim() === trimmed)) {
                        contentArr.push(line);
                    }
                }
            }
        }

        // Format final summary as Markdown
        const finalSummaryParts: string[] = [];
        let totalContentLines = 0;
        let emptyLecturesFound = 0;

        for (const [_, lecture] of mergedLectures) {
            if (lecture.content.length === 0) {
                console.warn(`[Analysis] âš ï¸ Sanity Check: Lecture "${lecture.title}" has no content!`);
                emptyLecturesFound++;
                continue;
            }

            let md = `## ${lecture.title}\n\n`;
            md += lecture.content.join('\n');
            totalContentLines += lecture.content.length;
            finalSummaryParts.push(md);
        }

        summary = finalSummaryParts.join('\n\n---\n\n');
        console.log(`[Analysis] Final summary length: ${summary.length} chars from ${mergedLectures.size} unique lectures, ${totalContentLines} content lines.`);

        // â”€â”€â”€ Phase 4.5: Final Sanity Check â”€â”€â”€
        if (mergedLectures.size < (totalChars / 50000)) {
            console.warn(`[Analysis] âš ï¸ Sanity Check: Extremely low lecture count (${mergedLectures.size}) relative to content size (${totalChars} chars).`);
        }
        if (totalContentLines < mergedLectures.size * 2) {
            console.warn(`[Analysis] âš ï¸ Sanity Check: Very few content lines (${totalContentLines}) for ${mergedLectures.size} lectures. Output may be sparse.`);
        }
        if (emptyLecturesFound > 0) {
            console.warn(`[Analysis] âš ï¸ Sanity Check: Dropped ${emptyLecturesFound} lectures because they had empty content.`);
        }

        // â•â•â• Step 4B: Generate QUIZZES + FOCUS + ESSAYS (as JSON) â•â•â•â•
        progress('analyzing', 'ÙŠÙˆÙ„Ù‘Ø¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆÙ†Ù‚Ø§Ø· Ø§Ù„ØªØ±ÙƒÙŠØ²...', 65);

        // Dynamic counts based on detected lectures
        const lectureCount = mergedLectures.size;
        const focusCount = Math.max(10, Math.min(20, lectureCount * 2));
        const quizCount = Math.max(15, Math.min(30, lectureCount * 3));
        const essayCount = Math.max(3, Math.min(8, lectureCount));
        console.log(`[Analysis] ${lectureCount} lectures â†’ ${focusCount} focus, ${quizCount} quiz, ${essayCount} essay`);

        // Build quiz content from FULL merged summary (covers entire book)
        // + audio content for focus extraction
        let quizContent = `=== Ù…Ù„Ø®Øµ Ø§Ù„ÙƒØªØ§Ø¨ Ø§Ù„Ø´Ø§Ù…Ù„ (ÙŠØºØ·ÙŠ ÙƒÙ„ Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø§Øª) ===\n\n${summary}`;

        if (sections.audio.length > 0) {
            quizContent += '\n\n=== Ø´Ø±Ø­ Ø§Ù„Ù…Ø¹Ù„Ù… ===\n\n';
            const audioText = sections.audio.map((s: any) => s.content).join('\n\n');
            if (audioText.length <= 80000) {
                quizContent += audioText;
            } else {
                const halfWindow = 40000;
                quizContent += `${audioText.slice(0, halfWindow)}\n\n...[Ø§Ù‚ØªØ·Ø§Ø¹]...\n\n${audioText.slice(-halfWindow)}`;
            }
        }

        // Cap total to stay within context
        if (quizContent.length > 200000) {
            quizContent = quizContent.substring(0, 200000) + '\n...(Ø§Ù‚ØªØ·Ø§Ø¹)';
        }

        const quizPrompt = `Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ§Ù„ÙŠ (Ù…Ù„Ø®Øµ ÙƒØªØ§Ø¨ ÙƒØ§Ù…Ù„ + Ø´Ø±Ø­ ØµÙˆØªÙŠ)ØŒ Ø£Ø®Ø±Ø¬ JSON ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰:

1. **focusPoints** (${focusCount} Ù†Ù‚Ø·Ø©) â€” Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ø­ÙˆØ±ÙŠØ© Ø§Ù„Ø£Ù‡Ù… ÙÙŠ Ø§Ù„ÙƒØªØ§Ø¨:
   - title: Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù†Ù‚Ø·Ø©
   - details: Ø´Ø±Ø­ ØªÙØµÙŠÙ„ÙŠ (150-300 ÙƒÙ„Ù…Ø©)

2. **quizzes** (${quizCount} Ø³Ø¤Ø§Ù„ Ù…ØªÙ†ÙˆØ¹ ÙŠØºØ·ÙŠ ÙƒÙ„ Ù…Ø­Ø§Ø¶Ø±Ø§Øª Ø§Ù„ÙƒØªØ§Ø¨):
   - question: Ø³Ø¤Ø§Ù„ Ù…Ø­Ø¯Ø¯ Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰
   - type: "mcq" Ø£Ùˆ "tf"
   - options: 4 Ø®ÙŠØ§Ø±Ø§Øª Ø¯Ø§Ø¦Ù…Ø§Ù‹ (Ø­ØªÙ‰ ØµØ­/Ø®Ø·Ø£: ["ØµØ­", "Ø®Ø·Ø£", "-", "-"])
   - correctAnswer: Ø±Ù‚Ù… (0,1,2,3)
   - explanation: Ø´Ø±Ø­ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©

3. **essayQuestions** (${essayCount} Ø³Ø¤Ø§Ù„ Ù…Ù‚Ø§Ù„ÙŠ):
   - question, idealAnswer (150-300 ÙƒÙ„Ù…Ø©)

âš ï¸ ÙˆØ²Ù‘Ø¹ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¹Ù„Ù‰ ÙƒÙ„ Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø§Øª Ø¨Ø§Ù„ØªØ³Ø§ÙˆÙŠ. correctAnswer = Ø±Ù‚Ù… ÙÙ‚Ø·. JSON Ù†Ù‚ÙŠ.

--- Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ---

${quizContent}`;

        let quizParsed: any = null;

        try {
            const quizResult = await callGeminiJSON(quizPrompt);
            quizParsed = normalizeResponse(quizResult.parsed);
            totalTokens += quizResult.tokensUsed;
        } catch (e: any) {
            console.warn(`[Analysis] âš ï¸ Gemini quizzes failed: ${e.message}. Trying GPT-4o...`);
            try {
                const gptResult = await callGPT4oJSON(quizPrompt);
                quizParsed = normalizeResponse(gptResult.parsed);
                totalTokens += gptResult.tokensUsed;
            } catch (e2: any) {
                console.warn(`[Analysis] âš ï¸ GPT-4o quizzes failed: ${e2.message}`);
                quizParsed = { focusPoints: [], quizzes: [], essayQuestions: [] };
            }
        }

        // â•â•â• Step 5: Save â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        progress('saving', 'Ø¬Ø§Ø±ÙŠ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...', 90);
        const analysisResult: AnalysisResult = {
            summary,
            focusPoints: quizParsed.focusPoints || [],
            quizzes: quizParsed.quizzes || [],
            essayQuestions: quizParsed.essayQuestions || [],
            metadata: {
                model: 'gemini-2.5-flash-split',
                contentStats: { pdfChars, audioChars, imageChars, method: finalMethod, focusMatches },
                generatedAt: new Date().toISOString(),
                schemaVersion: 7
            }
        };

        await supabase.from('lessons')
            .update({ analysis_result: analysisResult, analysis_status: 'completed' })
            .eq('id', lessonId);

        console.log(`[Analysis] âœ… Done: ${totalTokens} tokens, summary=${summary.length} chars, ${quizParsed.focusPoints?.length || 0} focus, ${quizParsed.quizzes?.length || 0} quiz, ${quizParsed.essayQuestions?.length || 0} essay`);
        return analysisResult;

    } catch (err: any) {
        console.error(`[Analysis] âŒ ${lessonId}: ${err.message}`);
        await supabase.from('lessons')
            .update({ analysis_status: 'failed', analysis_result: { error: err.message } })
            .eq('id', lessonId);
        throw err;
    }
}

export async function rerunLessonAnalysis(
    supabase: SupabaseClient<any, any, any>,
    lessonId: string
): Promise<AnalysisResult> {
    return generateLessonAnalysis(supabase, lessonId);
}
